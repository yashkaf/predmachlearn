---
title: "Predictive Modeling of Weight Lifting Exercises"
author: "Yakov Falkovich"
date: "Saturday, October 24, 2015"
output: html_document
---

## Qualitative Analysis of Exercise
The goal of this exercise is to classify weight lifting exercises preformed by different people into one of five types based on mistakes in exercise form. The data comes from wearable devices worn on different parts of the body. The five types refer to distinct movement categories and not to a discretization of any continuous measure. Thus, the models that I expect to give the best results are classification models (as opposed to regression models). 

The five categories refer to different body parts (i.e. Class E = "throwing the hips") and thus each type could be classified based on a specific group of body part variables. This encourages the use of tree models, I have decided to try both regular trees and random forest. 

```{r echo=FALSE}
library(caret);
library(ggplot2);
library(rattle);
```

## Basic Preprocessing
The data contains 160 variables, but many of them have missing values. We can reduce the number of relevant variables by excludes those with zero or near zero variance in either the training or the testing sets. 

```{r}
# Loading the data
trainraw=read.csv("pml-training.csv",header=T,sep=",")
testraw=read.csv("pml-testing.csv",header=T,sep=",")

# Removing zero variance variables
zvtest=nearZeroVar(testraw,saveMetrics=T)
zvtrain=nearZeroVar(trainraw,saveMetrics=T)
nzvs=zvtest[,3] | zvtest[,4] | zvtrain[,3] | zvtest[,4]
training=trainraw[,nzvs==F]
testing=testraw[,nzvs==F]

# The first six variables are irrelevant to prediction (e.g. name of participant)
training=training[7:59]
```

## Exploratory PCA
We are down to 52 predictor variables from 159, but it is still worth it to check whether the number of variables can be significantly reduced via PCA. We don't a lot of variables to be strongly correlated since each one refers to different motions (e.g. rolling vs. accelerating) or different body parts. Still, if PCA shows that almost the entire variance can be explained by only a few components it could worth trying a simple model with only those few.  

```{r echo=FALSE}
fullpc=princomp(~. -classe,data=training,cor=T,scale=T)
propvar=fullpc$sdev^2/52
qplot(x=1:52,y=propvar,size=3)+geom_abline(intercept=0,slope=0,color="red",size=2,alpha=0.5)+geom_abline(int=1/52,slo=0,color="blue",size=2,alpha=0.5)+annotate("text",x=26,y=.025,label="average component variance")+theme(legend.position="none")+labs(title="PCA Proportion of Variance",x="# of Component",y="Proportion of Total Variance")
```

PCA shows that most components contribute above zero variance, this is certainly true of the original variables so we should stick with them.

## Tree Model
I attempted to fit two tree models, one using the default parameters and one with a lower Complexity Parameter to increase the depth of the tree.  
```{r}
tremod1=train(classe~.,data=training,method="rpart")
tremod2=train(classe~.,data=training,method="rpart",cp=0.005)
```

Unfortunately, even the second model achieves a very poor accuracy of `r mean(tremod2$resample[,1])`. As we can see in a plot of the tree, it does not even classify any observation into class D:  
```{r echo=FALSE}
fancyRpartPlot(tremod2$finalModel,main="Simple Tree Model",sub="")
```

The failure of a simple tree model is likely due to the large number of variables, and the correct classification depending on complex interactions between them.

## Random Forest
By trying different combinations of variables, a random forest model can overcome the problems that plagued a simple tree.  

```{r}
rfmod=train(classe~.,data=training,method="rf",trControl=trainControl(number=5))
print(rfmod$finalModel)
```

As we see, the random forests model achieves excellent performance, trying about half the variables (27/52) at each point. The out of bag error rate estimate of 0.43% is unbiased, but might be a bit optimistic due to the nature of the data since all the examples given were central members of the respective categories (as assessed by professional fitness trainers). If this model is used to predict classification for exercises performed by other people and deal with boundary cases it's unlikely to remain above 99% accuracy, but we can't estimate that from the data given.

It's informative to look at the depths of the 500 trees generated by the random forest:  
```{r}
quantile(sapply(1:500, function(i) {dim(getTree(rfmod$finalModel,k=i))[1]}))
```
As we can see, it takes at least 1,000 nodes to get trees that are useful for prediction, showing how underpowered the 9-node simple tree model was.

## Conclusion
The random forest model does remarkably well on the task, giving an accuracy estimate of over 99% which is borne out by hitting 20 out of 20 on the testing set with the below predictions:  
```{r}
rfpred=predict(rfmod,testraw)
rfpred
```

The success of the random forest model was due to the richness of the data (52 relevant variables, thousands of dense observations). It's hard to extract an informative description of the prediction rule from such a model, but the failure of a simple tree model showed that it's unlikely that a simple description exists. Random forest is hard to interpret, but gives a highly accurate automated prediction.